# -*- coding: utf-8 -*-
"""model1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Il2OcllIWWepT09Be3qKWJmRjjlD9HWD
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import os

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

df1 = pd.read_csv('injury_data_clean.csv')
df2 = pd.read_csv('player_injuries_impact_clean.csv')

print("ğŸ“Š Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† injury_data_clean.csv:")
print(df1.head(), "\n")

print("ğŸ“Š Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† player_injuries_impact_clean.csv:")
print(df2.head(), "\n")

print("ğŸ” Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (injury_data_clean.csv):")
print(df1.info(), "\n")
print("ğŸ” Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (player_injuries_impact_clean.csv):")
print(df2.info(), "\n")

print("âŒ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ injury_data_clean.csv:")
print(df1.isnull().sum(), "\n")

print("âŒ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ player_injuries_impact_clean.csv:")
print(df2.isnull().sum(), "\n")

print("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (injury_data_clean.csv):")
print(df1.describe(), "\n")

print("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (player_injuries_impact_clean.csv):")
print(df2.describe(), "\n")

df = df1.copy("/content/player_injuries_impact_clean.csv")

X = df.drop('Likelihood_of_Injury', axis=1)
y = df['Likelihood_of_Injury']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("ğŸ“Š Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", acc)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

os.makedirs('/mnt/data/', exist_ok=True)

joblib.dump(model, '/mnt/data/player_injury_predictor_model.pkl')
print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³Ù…: player_injury_predictor_model.pkl")

y_pred = model.predict(X_test)

print("ğŸ” Ø£ÙˆÙ„ 10 Ù†ØªØ§Ø¦Ø¬ ØªÙ†Ø¨Ø¤:")
print(y_pred[:10])

print("ğŸ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¹Ù„ÙŠØ©:")
print(y_test.values[:10])

new_player = [[25, 75.0, 180.0, 1, 0.6, 3]]

model = joblib.load('/mnt/data/player_injury_predictor_model.pkl')

prediction = model.predict(new_player)
if prediction[0] == 1:
    print("âš ï¸ Ø§Ù„Ù„Ø§Ø¹Ø¨ Ù…Ø¹Ø±Ø¶ Ù„Ø®Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©")
else:
    print("âœ… Ø§Ù„Ù„Ø§Ø¹Ø¨ ØºÙŠØ± Ù…Ø¹Ø±Ø¶ Ù„Ø®Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©")

impact_df = pd.read_csv('/content/player_injuries_impact_clean.csv')

print(impact_df.columns.tolist())

def clean_rating(r):
    try:
        return float(str(r).replace('(S)', '').replace('N.A.', '').strip())
    except:
        return None

before_cols = ['Match1_before_injury_Player_rating', 'Match2_before_injury_Player_rating', 'Match3_before_injury_Player_rating']
after_cols = ['Match1_after_injury_Player_rating', 'Match2_after_injury_Player_rating', 'Match3_after_injury_Player_rating']

# Apply the cleaning function to the relevant columns
for col in before_cols:
    impact_df[col] = impact_df[col].apply(clean_rating)

for col in after_cols:
    impact_df[col] = impact_df[col].apply(clean_rating)

# Calculate and add 'Average_Before_Injury' column
impact_df['Average_Before_Injury'] = impact_df[[
    'Match1_before_injury_Player_rating',
    'Match2_before_injury_Player_rating',
    'Match3_before_injury_Player_rating'
]].mean(axis=1)

# Calculate and add 'Average_After_Injury' column
impact_df['Average_After_Injury'] = impact_df[[
    'Match1_after_injury_Player_rating',
    'Match2_after_injury_Player_rating',
    'Match3_after_injury_Player_rating'
]].mean(axis=1)

# Calculate and add 'Performance_Change' column
impact_df['Performance_Change'] = impact_df['Average_After_Injury'] - impact_df['Average_Before_Injury']

# Now you can access these columns:
impact_df[['Name', 'Average_Before_Injury', 'Average_After_Injury', 'Performance_Change']].head()

print(df.columns)

print(impact_df.columns.tolist())

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø©
before_cols = ['Match1_before_injury_Player_rating', 'Match2_before_injury_Player_rating', 'Match3_before_injury_Player_rating']
after_cols = ['Match1_after_injury_Player_rating', 'Match2_after_injury_Player_rating', 'Match3_after_injury_Player_rating']

# Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø¨Ù„ Ø§Ù„Ø¥ØµØ§Ø¨Ø©
impact_df['Avg_Rating_Before'] = impact_df[before_cols].mean(axis=1)

# Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø©
impact_df['Avg_Rating_After'] = impact_df[after_cols].mean(axis=1)

# Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø©
impact_df['Performance_Change'] = impact_df['Avg_Rating_After'] - impact_df['Avg_Rating_Before']

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
print(impact_df[['Name', 'Avg_Rating_Before', 'Avg_Rating_After', 'Performance_Change']].head())

impact_df['Avg_Rating_After'] = impact_df['Avg_Rating_After'].fillna(0)
impact_df['Performance_Change'] = impact_df['Performance_Change'].fillna(0)

impact_df.dropna(subset=['Avg_Rating_After', 'Performance_Change'], inplace=True)

impact_df['Avg_Rating_After'] = impact_df['Avg_Rating_After'].fillna(impact_df['Avg_Rating_After'].mean())
impact_df['Performance_Change'] = impact_df['Performance_Change'].fillna(impact_df['Performance_Change'].mean())

impact_df['Impact'] = impact_df['Performance_Change'].apply(lambda x: 'Improved' if x > 0 else 'Declined' if x < 0 else 'No Change')
impact_counts = impact_df['Impact'].value_counts()
print(impact_counts)

sns.histplot(impact_df['Performance_Change'].dropna(), bins=20, kde=True) # Changed df to impact_df
plt.title('Distribution of Performance Change After Injury')
plt.xlabel('Change in Rating (After - Before)')
plt.ylabel('Player Count')
plt.show()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
injury_df = pd.read_csv("injury_data_clean.csv")
impact_df = pd.read_csv("player_injuries_impact_clean.csv")

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ù…Ù„Ù impact (Ù…Ø«Ù„Ø§Ù‹ Ø§Ù„Ø¹Ù…Ø±ØŒ Ø§Ù„Ù…Ø±ÙƒØ²ØŒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…ØŒ Ø§Ù„Ø¥ØµØ§Ø¨Ø©...)
impact_df_subset = impact_df[['Name', 'Age', 'Position', 'FIFA rating', 'Injury']]

# Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³Ù… ÙƒÙ…Ø±Ø¬Ø¹ (ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡)
merged_df = pd.merge(injury_df, impact_df_subset, left_index=True, right_index=True)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (Ù…Ø«Ù„ Ø§Ù„Ù…Ø±ÙƒØ² Center Back â†’ Ø±Ù‚Ù…)
merged_df = pd.get_dummies(merged_df, columns=['Position', 'Injury'])

# ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù
X = merged_df.drop(['Likelihood_of_Injury', 'Name'], axis=1)
y = merged_df['Likelihood_of_Injury']

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred = model.predict(X_test)

# Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
print("ğŸ“Š Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

joblib.dump(model, 'injury_prediction_model.pkl')

risk_threshold = 0.7
predictions_df = pd.DataFrame(model.predict_proba(X)[:, 1], columns=['Injury_Risk'])
predictions_df['Alert'] = predictions_df['Injury_Risk'].apply(lambda x: 'âš ï¸ High Risk' if x > risk_threshold else 'âœ… Safe')
print(predictions_df.head())

accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x=y)
plt.title('Distribution of Injury Labels')
plt.show()
print(y.value_counts())

import xgboost as xgb
from sklearn.metrics import accuracy_score

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DMatrix (ØµÙŠØºØ© XGBoost)
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Hyperparameters)
params = {
    'objective': 'binary:logistic',  # Ù‡Ø¯Ù Ø«Ù†Ø§Ø¦ÙŠ (Ø¥ØµØ§Ø¨Ø© Ø£Ùˆ Ù„Ø§)
    'max_depth': 6,                  # Ø¹Ù…Ù‚ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±
    'eta': 0.1,                      # Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
    'eval_metric': 'logloss'         # Ù‚ÙŠØ§Ø³ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
}

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
bst = xgb.train(params, dtrain, num_boost_round=100)

# Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred = bst.predict(dtest)
y_pred = [1 if i > 0.5 else 0 for i in y_pred]  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¥Ù„Ù‰ 0 Ø£Ùˆ 1

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy (XGBoost): {accuracy}")

from sklearn.model_selection import GridSearchCV
import xgboost as xgb

# ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ù„Ù…Ø§Øª XGBoost
param_grid = {
    'max_depth': [3, 6, 10],
    'eta': [0.01, 0.1, 0.3],
    'n_estimators': [50, 100, 150],
    'subsample': [0.7, 0.8, 1.0]
}

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ XGBoost
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')

# ØªØ·Ø¨ÙŠÙ‚ GridSearchCV
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª
print("Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª:", grid_search.best_params_)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
best_model = grid_search.best_estimator_

# Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred = best_model.predict(X_test)

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
accuracy = accuracy_score(y_test, y_pred)
print(f"Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {accuracy}")

# Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø± (n_estimators)
from xgboost import XGBClassifier # Import XGBClassifier

param_grid = {
    'eta': [0.1],
    'max_depth': [10],
    'n_estimators': [100, 200],  # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±
    'subsample': [0.7]
}

# ØªØ·Ø¨ÙŠÙ‚ GridSearchCV Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=3, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙˆØ§Ù„Ø¯Ù‚Ø©
print("Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:", grid_search.best_params_)
print("Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ø¨Ø¹Ø¯ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:", grid_search.best_score_)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
duplicates = X_train.columns[X_train.columns.duplicated()]
print(duplicates)

# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
X_train = X_train.loc[:, ~X_train.columns.duplicated()]

grid_search_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=3, n_jobs=-1, scoring='accuracy')
grid_search_lgb.fit(X_train, y_train)

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„
best_model = grid_search.best_estimator_
joblib.dump(best_model, 'injury_prediction_model.pkl')

# ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
probs = best_model.predict_proba(X_test)[:, 1]  # Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¥ØµØ§Ø¨Ø©

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„Ø§Ø¹Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ø±Ø¶ÙŠÙ† Ù„Ù„Ø¥ØµØ§Ø¨Ø©
alert_threshold = 0.8
alerts = X_test[probs >= alert_threshold]
print("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª:", len(alerts))

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from joblib import load

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸
model = load('injury_prediction_model.pkl')

st.title("ØªÙ†Ø¨Ø¤ Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ù„Ø§Ø¹Ø¨ÙŠÙ†")

# Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª
uploaded_file = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", type=["csv", "xlsx"])
if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)
    st.write("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø©:", data.head())

    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª
    # This block is moved inside the 'if' to ensure data is defined
    predictions = model.predict(data)
    st.write("Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª:", predictions)
else:
    st.write("âš ï¸ Please upload a CSV or XLSX file.") # Inform the user if no file is uploaded

predictions_df.to_csv('predictions_output.csv', index=False)

# Ø±Ø³Ù… Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… seaborn
plt.figure(figsize=(10, 6))
sns.histplot(predictions_df['Injury_Risk'], kde=True, color='blue', bins=30)
plt.title('Distribution of Injury Risk')
plt.xlabel('Injury Risk')
plt.ylabel('Frequency')
plt.show()

# Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù„Ø§Ø¹Ø¨ÙŠÙ† ÙÙŠ ÙƒÙ„ ÙØ¦Ø©
risk_counts = predictions_df['Alert'].value_counts()

# Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¯Ø§Ø¦Ø±ÙŠ
plt.figure(figsize=(8, 8))
risk_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['red', 'green'])
plt.title('Player Risk Distribution')
plt.ylabel('')  # Ø¥Ø®ÙØ§Ø¡ Ø§Ù„ØªØ³Ù…ÙŠØ©
plt.show()

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
injury_data = pd.read_csv('injury_data_clean.csv')
player_injuries_impact = pd.read_csv('player_injuries_impact_clean.csv')

# Assuming 'Player_Age' in injury_data and 'Name' in player_injuries_impact
# represent the player identifier, modify the merge function:
merged_data = pd.merge(injury_data, player_injuries_impact, left_on='Player_Age', right_on='Age', how='inner')
# Replace 'Player_Age' and 'Age' with the correct column names if different

# Check if the merge is successful
print(merged_data.head())

# Ø±Ø³Ù… Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ© Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø§Ø±ØŒ Ø§Ù„ÙˆØ²Ù†ØŒ Ø´Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆÙ…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©
correlation_matrix = merged_data[['Player_Age', 'Player_Weight', 'Training_Intensity', 'Injury_Risk']].corr()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ©
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Injury Risk Factors')
plt.show()

# ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø±
risk_threshold = 0.7
merged_data['Alert'] = merged_data['Injury_Risk'].apply(lambda x: 'âš ï¸ High Risk' if x > risk_threshold else 'âœ… Safe')

plt.figure(figsize=(8, 6))
sns.scatterplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm')
plt.title('Training Intensity vs Injury Risk')
plt.xlabel('Training Intensity')
plt.ylabel('Injury Risk')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ DataFrame
# merged_data ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø«Ù„ 'Fatigue_Level' Ùˆ 'Injury_Risk' Ùˆ 'Alert'

# Ø±Ø³Ù… scatter plot ÙŠÙˆØ¶Ø­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ø¨ (Fatigue Level) ÙˆÙ…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø© (Injury Risk)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Fatigue_Level', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm', style='Alert', markers={'âš ï¸ High Risk': 'X', 'âœ… Safe': 'o'})
plt.title('Fatigue Level vs Injury Risk with Alerts')
plt.xlabel('Fatigue Level')
plt.ylabel('Injury Risk')
plt.legend(title='Risk Level', loc='upper right')
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 6))

# Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø¥ØµØ§Ø¨Ø© ÙÙŠ Ø£ÙˆÙ„ Ù…Ø¨Ø§Ø±Ø§Ø©
sns.lineplot(data=merged_data, x=merged_data.index, y='Match1_before_injury_Result', label='Before Injury', marker='o', color='blue')
sns.lineplot(data=merged_data, x=merged_data.index, y='Match1_after_injury_Result', label='After Injury', marker='o', color='red')

plt.title('Performance Comparison Before and After Injury (Match 1)')
plt.xlabel('Player Index')
plt.ylabel('Performance Result')
plt.legend(labels=['Before Injury', 'After Injury'])
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

# Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ© ØªØ¸Ù‡Ø± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† "ÙˆØ²Ù† Ø§Ù„Ù„Ø§Ø¹Ø¨" Ùˆ "Ø´Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨" Ùˆ "Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©"
correlation_matrix = merged_data[['Player_Weight', 'Training_Intensity', 'Injury_Risk']].corr()

# Ø±Ø³Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ©
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Player Weight, Training Intensity, and Injury Risk')
plt.show()

plt.figure(figsize=(12, 8))

# Ø±Ø³Ù… boxplot ÙŠÙˆØ¶Ø­ ØªØ£Ø«ÙŠØ± Ø´Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø®Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©
sns.boxplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, palette='Set2')

plt.title('Impact of Training Intensity on Injury Risk', fontsize=16)
plt.xlabel('Training Intensity', fontsize=14)
plt.ylabel('Injury Risk', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

# Ø±Ø³Ù… Scatterplot Ø¨ÙŠÙ† "Ø´Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨" Ùˆ "Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¥ØµØ§Ø¨Ø©"
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm')
plt.title('Training Intensity vs Injury Risk')
plt.xlabel('Training Intensity')
plt.ylabel('Injury Risk')
plt.show()

