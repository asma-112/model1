# -*- coding: utf-8 -*-
"""model1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Il2OcllIWWepT09Be3qKWJmRjjlD9HWD
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import os

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

df1 = pd.read_csv('injury_data_clean.csv')
df2 = pd.read_csv('player_injuries_impact_clean.csv')

print("📊 أول 5 صفوف من injury_data_clean.csv:")
print(df1.head(), "\n")

print("📊 أول 5 صفوف من player_injuries_impact_clean.csv:")
print(df2.head(), "\n")

print("🔍 معلومات عن الأعمدة (injury_data_clean.csv):")
print(df1.info(), "\n")
print("🔍 معلومات عن الأعمدة (player_injuries_impact_clean.csv):")
print(df2.info(), "\n")

print("❌ القيم المفقودة في injury_data_clean.csv:")
print(df1.isnull().sum(), "\n")

print("❌ القيم المفقودة في player_injuries_impact_clean.csv:")
print(df2.isnull().sum(), "\n")

print("📈 إحصائيات (injury_data_clean.csv):")
print(df1.describe(), "\n")

print("📈 إحصائيات (player_injuries_impact_clean.csv):")
print(df2.describe(), "\n")

df = df1.copy("/content/player_injuries_impact_clean.csv")

X = df.drop('Likelihood_of_Injury', axis=1)
y = df['Likelihood_of_Injury']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("📊 دقة النموذج:", acc)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

os.makedirs('/mnt/data/', exist_ok=True)

joblib.dump(model, '/mnt/data/player_injury_predictor_model.pkl')
print("✅ تم حفظ النموذج باسم: player_injury_predictor_model.pkl")

y_pred = model.predict(X_test)

print("🔍 أول 10 نتائج تنبؤ:")
print(y_pred[:10])

print("🎯 القيم الفعلية:")
print(y_test.values[:10])

new_player = [[25, 75.0, 180.0, 1, 0.6, 3]]

model = joblib.load('/mnt/data/player_injury_predictor_model.pkl')

prediction = model.predict(new_player)
if prediction[0] == 1:
    print("⚠️ اللاعب معرض لخطر الإصابة")
else:
    print("✅ اللاعب غير معرض لخطر الإصابة")

impact_df = pd.read_csv('/content/player_injuries_impact_clean.csv')

print(impact_df.columns.tolist())

def clean_rating(r):
    try:
        return float(str(r).replace('(S)', '').replace('N.A.', '').strip())
    except:
        return None

before_cols = ['Match1_before_injury_Player_rating', 'Match2_before_injury_Player_rating', 'Match3_before_injury_Player_rating']
after_cols = ['Match1_after_injury_Player_rating', 'Match2_after_injury_Player_rating', 'Match3_after_injury_Player_rating']

# Apply the cleaning function to the relevant columns
for col in before_cols:
    impact_df[col] = impact_df[col].apply(clean_rating)

for col in after_cols:
    impact_df[col] = impact_df[col].apply(clean_rating)

# Calculate and add 'Average_Before_Injury' column
impact_df['Average_Before_Injury'] = impact_df[[
    'Match1_before_injury_Player_rating',
    'Match2_before_injury_Player_rating',
    'Match3_before_injury_Player_rating'
]].mean(axis=1)

# Calculate and add 'Average_After_Injury' column
impact_df['Average_After_Injury'] = impact_df[[
    'Match1_after_injury_Player_rating',
    'Match2_after_injury_Player_rating',
    'Match3_after_injury_Player_rating'
]].mean(axis=1)

# Calculate and add 'Performance_Change' column
impact_df['Performance_Change'] = impact_df['Average_After_Injury'] - impact_df['Average_Before_Injury']

# Now you can access these columns:
impact_df[['Name', 'Average_Before_Injury', 'Average_After_Injury', 'Performance_Change']].head()

print(df.columns)

print(impact_df.columns.tolist())

# تحديد الأعمدة الخاصة بتقييمات الأداء قبل وبعد الإصابة
before_cols = ['Match1_before_injury_Player_rating', 'Match2_before_injury_Player_rating', 'Match3_before_injury_Player_rating']
after_cols = ['Match1_after_injury_Player_rating', 'Match2_after_injury_Player_rating', 'Match3_after_injury_Player_rating']

# حساب متوسط الأداء قبل الإصابة
impact_df['Avg_Rating_Before'] = impact_df[before_cols].mean(axis=1)

# حساب متوسط الأداء بعد الإصابة
impact_df['Avg_Rating_After'] = impact_df[after_cols].mean(axis=1)

# حساب الفرق بين الأداء قبل وبعد الإصابة
impact_df['Performance_Change'] = impact_df['Avg_Rating_After'] - impact_df['Avg_Rating_Before']

# عرض النتائج الأولية
print(impact_df[['Name', 'Avg_Rating_Before', 'Avg_Rating_After', 'Performance_Change']].head())

impact_df['Avg_Rating_After'] = impact_df['Avg_Rating_After'].fillna(0)
impact_df['Performance_Change'] = impact_df['Performance_Change'].fillna(0)

impact_df.dropna(subset=['Avg_Rating_After', 'Performance_Change'], inplace=True)

impact_df['Avg_Rating_After'] = impact_df['Avg_Rating_After'].fillna(impact_df['Avg_Rating_After'].mean())
impact_df['Performance_Change'] = impact_df['Performance_Change'].fillna(impact_df['Performance_Change'].mean())

impact_df['Impact'] = impact_df['Performance_Change'].apply(lambda x: 'Improved' if x > 0 else 'Declined' if x < 0 else 'No Change')
impact_counts = impact_df['Impact'].value_counts()
print(impact_counts)

sns.histplot(impact_df['Performance_Change'].dropna(), bins=20, kde=True) # Changed df to impact_df
plt.title('Distribution of Performance Change After Injury')
plt.xlabel('Change in Rating (After - Before)')
plt.ylabel('Player Count')
plt.show()

# تحميل البيانات
injury_df = pd.read_csv("injury_data_clean.csv")
impact_df = pd.read_csv("player_injuries_impact_clean.csv")

# تحديد الأعمدة المهمة من ملف impact (مثلاً العمر، المركز، التقييم، الإصابة...)
impact_df_subset = impact_df[['Name', 'Age', 'Position', 'FIFA rating', 'Injury']]

# دمج البيانات باستخدام الاسم كمرجع (تأكد من تطابق الأسماء)
merged_df = pd.merge(injury_df, impact_df_subset, left_index=True, right_index=True)

# تحويل الأعمدة النصية إلى أرقام (مثل المركز Center Back → رقم)
merged_df = pd.get_dummies(merged_df, columns=['Position', 'Injury'])

# فصل الميزات عن الهدف
X = merged_df.drop(['Likelihood_of_Injury', 'Name'], axis=1)
y = merged_df['Likelihood_of_Injury']

# تقسيم البيانات
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# إنشاء الموديل
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# التنبؤ
y_pred = model.predict(X_test)

# التقييم
print("📊 Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

joblib.dump(model, 'injury_prediction_model.pkl')

risk_threshold = 0.7
predictions_df = pd.DataFrame(model.predict_proba(X)[:, 1], columns=['Injury_Risk'])
predictions_df['Alert'] = predictions_df['Injury_Risk'].apply(lambda x: '⚠️ High Risk' if x > risk_threshold else '✅ Safe')
print(predictions_df.head())

accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x=y)
plt.title('Distribution of Injury Labels')
plt.show()
print(y.value_counts())

import xgboost as xgb
from sklearn.metrics import accuracy_score

# تحويل البيانات إلى DMatrix (صيغة XGBoost)
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# تحديد المعاملات (Hyperparameters)
params = {
    'objective': 'binary:logistic',  # هدف ثنائي (إصابة أو لا)
    'max_depth': 6,                  # عمق الأشجار
    'eta': 0.1,                      # معدل التعلم
    'eval_metric': 'logloss'         # قياس الخسارة
}

# تدريب النموذج
bst = xgb.train(params, dtrain, num_boost_round=100)

# التنبؤ
y_pred = bst.predict(dtest)
y_pred = [1 if i > 0.5 else 0 for i in y_pred]  # تحويل الاحتمالات إلى 0 أو 1

# حساب الدقة
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy (XGBoost): {accuracy}")

from sklearn.model_selection import GridSearchCV
import xgboost as xgb

# تحديد معلمات XGBoost
param_grid = {
    'max_depth': [3, 6, 10],
    'eta': [0.01, 0.1, 0.3],
    'n_estimators': [50, 100, 150],
    'subsample': [0.7, 0.8, 1.0]
}

# تهيئة النموذج XGBoost
xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')

# تطبيق GridSearchCV
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# أفضل المعلمات
print("أفضل المعلمات:", grid_search.best_params_)

# استخدام أفضل المعلمات لتدريب الموديل
best_model = grid_search.best_estimator_

# التنبؤ
y_pred = best_model.predict(X_test)

# حساب الدقة
accuracy = accuracy_score(y_test, y_pred)
print(f"أفضل دقة بعد تحسين المعاملات: {accuracy}")

# زيادة عدد الأشجار (n_estimators)
from xgboost import XGBClassifier # Import XGBClassifier

param_grid = {
    'eta': [0.1],
    'max_depth': [10],
    'n_estimators': [100, 200],  # زيادة عدد الأشجار
    'subsample': [0.7]
}

# تطبيق GridSearchCV مرة أخرى
grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=3, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)

# أفضل المعاملات والدقة
print("أفضل المعاملات:", grid_search.best_params_)
print("أفضل دقة بعد تحسين المعاملات:", grid_search.best_score_)

# التحقق من الأعمدة المكررة
duplicates = X_train.columns[X_train.columns.duplicated()]
print(duplicates)

# إزالة الأعمدة المكررة
X_train = X_train.loc[:, ~X_train.columns.duplicated()]

grid_search_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=3, n_jobs=-1, scoring='accuracy')
grid_search_lgb.fit(X_train, y_train)

# حفظ النموذج الأفضل
best_model = grid_search.best_estimator_
joblib.dump(best_model, 'injury_prediction_model.pkl')

# توقع الاحتمالات
probs = best_model.predict_proba(X_test)[:, 1]  # احتمال الإصابة

# تحديد اللاعبين المعرضين للإصابة
alert_threshold = 0.8
alerts = X_test[probs >= alert_threshold]
print("عدد التنبيهات:", len(alerts))

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from joblib import load

# تحميل النموذج المحفوظ
model = load('injury_prediction_model.pkl')

st.title("تنبؤ الإصابات في اللاعبين")

# رفع البيانات لتنبؤ الإصابات
uploaded_file = st.file_uploader("رفع البيانات", type=["csv", "xlsx"])
if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)
    st.write("البيانات المدخلة:", data.head())

    # التنبؤ بالإصابات
    # This block is moved inside the 'if' to ensure data is defined
    predictions = model.predict(data)
    st.write("التنبؤات:", predictions)
else:
    st.write("⚠️ Please upload a CSV or XLSX file.") # Inform the user if no file is uploaded

predictions_df.to_csv('predictions_output.csv', index=False)

# رسم التوزيع باستخدام seaborn
plt.figure(figsize=(10, 6))
sns.histplot(predictions_df['Injury_Risk'], kde=True, color='blue', bins=30)
plt.title('Distribution of Injury Risk')
plt.xlabel('Injury Risk')
plt.ylabel('Frequency')
plt.show()

# حساب عدد اللاعبين في كل فئة
risk_counts = predictions_df['Alert'].value_counts()

# رسم بياني دائري
plt.figure(figsize=(8, 8))
risk_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['red', 'green'])
plt.title('Player Risk Distribution')
plt.ylabel('')  # إخفاء التسمية
plt.show()

# قراءة البيانات
injury_data = pd.read_csv('injury_data_clean.csv')
player_injuries_impact = pd.read_csv('player_injuries_impact_clean.csv')

# Assuming 'Player_Age' in injury_data and 'Name' in player_injuries_impact
# represent the player identifier, modify the merge function:
merged_data = pd.merge(injury_data, player_injuries_impact, left_on='Player_Age', right_on='Age', how='inner')
# Replace 'Player_Age' and 'Age' with the correct column names if different

# Check if the merge is successful
print(merged_data.head())

# رسم خريطة حرارية لبيانات العلاقة بين الأعمار، الوزن، شدة التدريب، ومخاطر الإصابة
correlation_matrix = merged_data[['Player_Age', 'Player_Weight', 'Training_Intensity', 'Injury_Risk']].corr()

# رسم الخريطة الحرارية
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Injury Risk Factors')
plt.show()

# تعيين قيمة التنبيه بناءً على مستوى الخطر
risk_threshold = 0.7
merged_data['Alert'] = merged_data['Injury_Risk'].apply(lambda x: '⚠️ High Risk' if x > risk_threshold else '✅ Safe')

plt.figure(figsize=(8, 6))
sns.scatterplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm')
plt.title('Training Intensity vs Injury Risk')
plt.xlabel('Training Intensity')
plt.ylabel('Injury Risk')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# تأكد من أن لديك البيانات المناسبة في DataFrame
# merged_data يحتوي على البيانات المطلوبة مثل 'Fatigue_Level' و 'Injury_Risk' و 'Alert'

# رسم scatter plot يوضح العلاقة بين مستوى التعب (Fatigue Level) ومخاطر الإصابة (Injury Risk)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Fatigue_Level', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm', style='Alert', markers={'⚠️ High Risk': 'X', '✅ Safe': 'o'})
plt.title('Fatigue Level vs Injury Risk with Alerts')
plt.xlabel('Fatigue Level')
plt.ylabel('Injury Risk')
plt.legend(title='Risk Level', loc='upper right')
plt.grid(True)
plt.show()

plt.figure(figsize=(12, 6))

# رسم مقارنة بين الأداء قبل وبعد الإصابة في أول مباراة
sns.lineplot(data=merged_data, x=merged_data.index, y='Match1_before_injury_Result', label='Before Injury', marker='o', color='blue')
sns.lineplot(data=merged_data, x=merged_data.index, y='Match1_after_injury_Result', label='After Injury', marker='o', color='red')

plt.title('Performance Comparison Before and After Injury (Match 1)')
plt.xlabel('Player Index')
plt.ylabel('Performance Result')
plt.legend(labels=['Before Injury', 'After Injury'])
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

# إنشاء خريطة حرارية تظهر العلاقة بين "وزن اللاعب" و "شدة التدريب" و "مخاطر الإصابة"
correlation_matrix = merged_data[['Player_Weight', 'Training_Intensity', 'Injury_Risk']].corr()

# رسم الخريطة الحرارية
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Player Weight, Training Intensity, and Injury Risk')
plt.show()

plt.figure(figsize=(12, 8))

# رسم boxplot يوضح تأثير شدة التدريب على خطر الإصابة
sns.boxplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, palette='Set2')

plt.title('Impact of Training Intensity on Injury Risk', fontsize=16)
plt.xlabel('Training Intensity', fontsize=14)
plt.ylabel('Injury Risk', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

# رسم Scatterplot بين "شدة التدريب" و "مخاطر الإصابة"
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Training_Intensity', y='Injury_Risk', data=merged_data, hue='Alert', palette='coolwarm')
plt.title('Training Intensity vs Injury Risk')
plt.xlabel('Training Intensity')
plt.ylabel('Injury Risk')
plt.show()

